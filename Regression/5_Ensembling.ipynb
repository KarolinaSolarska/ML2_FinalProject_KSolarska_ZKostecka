{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model IV : Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the last model of this part of the project. We will used estimated models to perform an ensembling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = pd.read_csv('data/data_after_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_rented_bike_count, lambda_best_fit = stats.boxcox(data5['rented_bike_count'])\n",
    "\n",
    "boxcox_target = pd.DataFrame()\n",
    "boxcox_target['boxcox_rented_bike_count'] = transformed_rented_bike_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data5.drop(columns=['rented_bike_count']) \n",
    "y_t = boxcox_target['boxcox_rented_bike_count'] # _t stands for transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7458"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train_t, y_test_t = train_test_split(X, y_t, test_size=0.3, random_state=123)\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reverse from box-cox transformed values to the real interpretable values please see the ensembling script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Copy paste the best models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_rf = {\n",
    "    'max_depth': 20,\n",
    "    'min_samples_leaf': 3,\n",
    "    'min_samples_split': 7,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "best_rf_regressor5 = RandomForestRegressor(random_state=123, **best_params_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = {\n",
    "'colsample_bytree': 0.9,\n",
    " 'learning_rate': 0.01,\n",
    " 'max_depth': 8,\n",
    " 'n_estimators': 1400,\n",
    " 'subsample': 0.8\n",
    " }\n",
    "\n",
    "best_xgb_model4 = xgb.XGBRegressor(**best_params_xgb, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_dtr = {\n",
    "    'max_depth': 30,\n",
    "    'min_samples_leaf': 3, \n",
    "    'min_samples_split': 9}\n",
    "\n",
    "best_regressor2 = DecisionTreeRegressor(**best_params_dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGB</th>\n",
       "      <th>DTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.259062</td>\n",
       "      <td>10.241086</td>\n",
       "      <td>10.369159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.749179</td>\n",
       "      <td>14.765772</td>\n",
       "      <td>14.572358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.071292</td>\n",
       "      <td>13.074230</td>\n",
       "      <td>13.225625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.339373</td>\n",
       "      <td>14.550099</td>\n",
       "      <td>14.075066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.281739</td>\n",
       "      <td>15.578500</td>\n",
       "      <td>15.467207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7453</th>\n",
       "      <td>15.467101</td>\n",
       "      <td>15.649019</td>\n",
       "      <td>15.563404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>8.747498</td>\n",
       "      <td>8.887631</td>\n",
       "      <td>8.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>14.104087</td>\n",
       "      <td>14.157540</td>\n",
       "      <td>13.871781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7456</th>\n",
       "      <td>11.181591</td>\n",
       "      <td>11.195338</td>\n",
       "      <td>11.229902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7457</th>\n",
       "      <td>10.662368</td>\n",
       "      <td>10.723182</td>\n",
       "      <td>10.320287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7458 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Random Forest        XGB        DTR\n",
       "0         10.259062  10.241086  10.369159\n",
       "1         14.749179  14.765772  14.572358\n",
       "2         13.071292  13.074230  13.225625\n",
       "3         14.339373  14.550099  14.075066\n",
       "4         15.281739  15.578500  15.467207\n",
       "...             ...        ...        ...\n",
       "7453      15.467101  15.649019  15.563404\n",
       "7454       8.747498   8.887631   8.814815\n",
       "7455      14.104087  14.157540  13.871781\n",
       "7456      11.181591  11.195338  11.229902\n",
       "7457      10.662368  10.723182  10.320287\n",
       "\n",
       "[7458 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'Random Forest' : RandomForestRegressor(random_state=123, **best_params_rf),\n",
    "                        'XGB' :  xgb.XGBRegressor(**best_params_xgb, random_state=123),\n",
    "                         'DTR' :  DecisionTreeRegressor(**best_params_dtr, random_state=123)}\n",
    "\n",
    "\n",
    "predictions_df = pd.DataFrame()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "\n",
    "    model.fit(X_train, y_train_t)\n",
    "    train_predictions = model.predict(X_train)\n",
    "    \n",
    "    predictions_df[model_name] = train_predictions\n",
    "\n",
    "predictions_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zuzanna/opt/anaconda3/lib/python3.9/site-packages/vecstack/core.py:461: UserWarning: This is regression task hence classification-specific parameters set to <True> were ignored: <stratified>\n",
      "  warnings.warn(warn_str, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [regression]\n",
      "metric:       [custom_mae]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [RandomForestRegressor]\n",
      "    fold  0:  [0.61222189]\n",
      "    fold  1:  [0.63121820]\n",
      "    fold  2:  [0.64083715]\n",
      "    fold  3:  [0.66761426]\n",
      "    fold  4:  [0.65088324]\n",
      "    ----\n",
      "    MEAN:     [0.64055495] + [0.01859514]\n",
      "    FULL:     [0.64054993]\n",
      "\n",
      "model  1:     [XGBRegressor]\n",
      "    fold  0:  [0.52995083]\n",
      "    fold  1:  [0.53645839]\n",
      "    fold  2:  [0.53397705]\n",
      "    fold  3:  [0.56033081]\n",
      "    fold  4:  [0.54490790]\n",
      "    ----\n",
      "    MEAN:     [0.54112499] + [0.01077874]\n",
      "    FULL:     [0.54112191]\n",
      "\n",
      "model  2:     [DecisionTreeRegressor]\n",
      "    fold  0:  [0.79069244]\n",
      "    fold  1:  [0.78081929]\n",
      "    fold  2:  [0.79229353]\n",
      "    fold  3:  [0.82547695]\n",
      "    fold  4:  [0.84446634]\n",
      "    ----\n",
      "    MEAN:     [0.80674971] + [0.02413486]\n",
      "    FULL:     [0.80674214]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vecstack import stacking\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "models = [RandomForestRegressor(random_state=123, **best_params_rf), \n",
    "          xgb.XGBRegressor(**best_params_xgb, random_state=123),\n",
    "          DecisionTreeRegressor(**best_params_dtr, random_state=123)]\n",
    "\n",
    "\n",
    "S_Train, S_test = stacking(models,                   \n",
    "                           X_train, y_train_t, X_test,   \n",
    "                           regression=True,\n",
    "                           mode='oof_pred_bag',\n",
    "                           needs_proba=False,\n",
    "                           save_dir=None, \n",
    "                           metric= custom_mae, \n",
    "                           n_folds=5, \n",
    "                           stratified=True,\n",
    "                           shuffle=True, \n",
    "                           random_state=123, \n",
    "                           verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already trained our models and applied the cross-validation, we can use the sklearn package (which do not utilize any CV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('rf', RandomForestRegressor(random_state=123, **best_params_rf)),\n",
    "    ('xgb', xgb.XGBRegressor(**best_params_xgb, random_state=123)),\n",
    "    ('dtr', DecisionTreeRegressor(**best_params_dtr, random_state=123))\n",
    "    ]\n",
    "meta_model = xgb.XGBRegressor(**best_params_xgb, random_state=123)\n",
    "\n",
    "# Create the StackingRegressor\n",
    "stacking_regressor = StackingRegressor(estimators=models, final_estimator=meta_model)\n",
    "stacking_regressor.fit(X_train, y_train_t)\n",
    "\n",
    "# Evaluate the StackingRegressor \n",
    "score = stacking_regressor.score(X_test, y_test_t)\n",
    "\n",
    "# Make predictions using the meta-model\n",
    "y_pred = stacking_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluate the stacking model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_mape_scorer(y_true, y_pred):\n",
    "    ape = abs((y_true - y_pred) / y_true) * 100\n",
    "    return np.mean(ape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.566 (0.029) Mean MSE: 0.838\n",
      "MAPE scores: [7.12125442 7.01969374 6.33868515 6.58329872 7.42769338]\n",
      "Mean MAPE: 6.89812508306818\n"
     ]
    }
   ],
   "source": [
    "scores_mae = cross_val_score(stacking_regressor, X_train, y_train_t, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "scores_mse = cross_val_score(stacking_regressor, X_train, y_train_t, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "scores_mae = abs(scores_mae)\n",
    "scores_mse = abs(scores_mse)\n",
    "\n",
    "print('Mean MAE: %.3f (%.3f) Mean MSE: %.3f' % (scores_mae.mean(), scores_mae.std(), scores_mse.mean()) )\n",
    "\n",
    "mape_scores = cross_val_score(stacking_regressor, X_train, y_train_t, cv=5, scoring=make_scorer(custom_mape_scorer))\n",
    "\n",
    "print(\"MAPE scores:\", mape_scores)\n",
    "print(\"Mean MAPE:\", np.mean(mape_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking model was performed using the target variable with Boc-Cox transformation. Surpisingly, its performance was worse in relation to the meta model: XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Final prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 0.705 (0.053) Mean MSE: 1.191\n",
      "MAPE scores: [8.0657022  8.90722287 7.83579876 8.34958414 9.55975083]\n",
      "Mean MAPE: 8.543611758396105\n"
     ]
    }
   ],
   "source": [
    "scores_mae = cross_val_score(stacking_regressor, X_test, y_test_t, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "scores_mse = cross_val_score(stacking_regressor, X_test, y_test_t, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "scores_mae = abs(scores_mae)\n",
    "scores_mse = abs(scores_mse)\n",
    "\n",
    "print('Mean MAE: %.3f (%.3f) Mean MSE: %.3f' % (scores_mae.mean(), scores_mae.std(), scores_mse.mean()) )\n",
    "\n",
    "mape_scores = cross_val_score(stacking_regressor, X_test, y_test_t, cv=5, scoring=make_scorer(custom_mape_scorer))\n",
    "\n",
    "print(\"MAPE scores:\", mape_scores)\n",
    "print(\"Mean MAPE:\", np.mean(mape_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = stacking_regressor.predict(X_test)  \n",
    "y_test_pred = pd.DataFrame(y_test_pred)\n",
    "y_test_pred.to_csv('y_pred_STACK.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
